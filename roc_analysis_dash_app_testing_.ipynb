{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOCr+NM+Seuq2jZ4hv66KZz",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/dhynasah/dg_coding_interview/blob/main/roc_analysis_dash_app_testing_.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "5rDTy4_LR0uT"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from typing import Union\n",
        "\n",
        "\n",
        "class ADFCalculations:\n",
        "    \"\"\"\n",
        "    A class used to parse and store data related to a NeuMoDx ADF RawDataExport File\n",
        "    \"\"\"\n",
        "\n",
        "    settings_df = pd.DataFrame\n",
        "\n",
        "    def __init__(\n",
        "        self,\n",
        "        sample_key: pd.DataFrame,\n",
        "        adf_df: pd.DataFrame,\n",
        "        parameter: str,\n",
        "        channel: str,\n",
        "        specimen_type: str,\n",
        "        increment_list: list,\n",
        "    ) -> None:\n",
        "        self.sample_key = pd.DataFrame(sample_key)\n",
        "        self.adf_df = pd.DataFrame(adf_df)\n",
        "        self.parameter = parameter\n",
        "        self.specimen_type = specimen_type\n",
        "        self.channel = channel\n",
        "        self.increment_list = increment_list\n",
        "        self.increment_calculations()\n",
        "\n",
        "    @staticmethod\n",
        "    def check_cutoffs(sk_group_df: pd.DataFrame, adf_df: pd.DataFrame) -> pd.DataFrame:\n",
        "        \"\"\"This function takes 2 dataframes, sample_key and adf_df and\n",
        "\n",
        "        Args:\n",
        "            sk_group_df: a dataframe created from group_by where all the rows have the\n",
        "             same target name and specimen type\n",
        "            adf_df: a dataframe that has been modified by the adfparser class\n",
        "        Returns:\n",
        "            a pandas dataframe with a new column, simulated target result\n",
        "\n",
        "        \"\"\"\n",
        "        sk_group_df = sk_group_df.copy()\n",
        "        target_name_list = list(sk_group_df[\"Target Name\"].unique())\n",
        "        target_name_str = \"\"\n",
        "        target_name = target_name_str.join(target_name_list)\n",
        "        specimen_type_list = list(sk_group_df[\"Target Setting Specimen Type\"].unique())\n",
        "        specimen_type_str = \"\"\n",
        "        specimen_type = specimen_type_str.join(specimen_type_list)\n",
        "\n",
        "        min_peak_height = adf_df[\n",
        "            (adf_df[\"TargetName\"] == target_name)\n",
        "            & (adf_df[\"SpecimenType\"] == specimen_type)\n",
        "        ][\"Minimum Peak Height\"].values[0]\n",
        "\n",
        "        min_EPF = adf_df[\n",
        "            (adf_df[\"TargetName\"] == target_name)\n",
        "            & (adf_df[\"SpecimenType\"] == specimen_type)\n",
        "        ][\"Minimum End Point Fluorescence\"].values[0]\n",
        "\n",
        "        peak_max_cycle = adf_df[\n",
        "            (adf_df[\"TargetName\"] == target_name)\n",
        "            & (adf_df[\"SpecimenType\"] == specimen_type)\n",
        "        ][\"Peak Maximum Cycle\"].values[0]\n",
        "\n",
        "        overall_threshold = adf_df[\n",
        "            (adf_df[\"TargetName\"] == target_name)\n",
        "            & (adf_df[\"SpecimenType\"] == specimen_type)\n",
        "        ][\"Overall EPR Threshold\"].values[0]\n",
        "\n",
        "        EPR_check_ct_threshold = adf_df[\n",
        "            (adf_df[\"TargetName\"] == target_name)\n",
        "            & (adf_df[\"SpecimenType\"] == specimen_type)\n",
        "        ][\"EPR Check Ct Threshold\"].values[0]\n",
        "\n",
        "        EPR_threshold = adf_df[\n",
        "            (adf_df[\"TargetName\"] == target_name)\n",
        "            & (adf_df[\"SpecimenType\"] == specimen_type)\n",
        "        ][\"EPR Threshold\"].values[0]\n",
        "        sk_group_df[\"Max Peak Height\"] = sk_group_df[\"Max Peak Height\"].replace(\n",
        "            \"\", np.nan, regex=True\n",
        "        )\n",
        "        sk_group_df[\"End Point Fluorescence\"] = sk_group_df[\n",
        "            \"End Point Fluorescence\"\n",
        "        ].replace(\"\", np.nan, regex=True)\n",
        "        sk_group_df[\"Ct\"] = sk_group_df[\"Ct\"].replace(\"\", np.nan, regex=True)\n",
        "        sk_group_df[\"EPR\"] = sk_group_df[\"EPR\"].replace(\"\", np.nan, regex=True)\n",
        "\n",
        "        sk_group_df[\"Observed Result\"] = np.where(\n",
        "            (\n",
        "                (sk_group_df[\"Max Peak Height\"] > min_peak_height)\n",
        "                & (sk_group_df[\"End Point Fluorescence\"] > min_EPF)\n",
        "                & (sk_group_df[\"Ct\"] <= peak_max_cycle + 0.5)\n",
        "                & (sk_group_df[\"EPR\"] >= overall_threshold)\n",
        "                & (\n",
        "                    (sk_group_df[\"Ct\"] > EPR_check_ct_threshold)\n",
        "                    | (\n",
        "                        (sk_group_df[\"Ct\"] <= EPR_check_ct_threshold)\n",
        "                        & (sk_group_df[\"EPR\"] > EPR_threshold)\n",
        "                    )\n",
        "                )\n",
        "            ),\n",
        "            \"POS\",\n",
        "            \"NEG\",\n",
        "        )\n",
        "        return sk_group_df\n",
        "\n",
        "    def group_by_cutoffs(\n",
        "        self, sample_key: pd.DataFrame, adf_df: pd.DataFrame\n",
        "    ) -> pd.DataFrame:\n",
        "        \"\"\"\n",
        "\n",
        "        Args:\n",
        "            sample_key: dataframe with all samples\n",
        "            adf_df:a dataframe that has been modified by the adfparser class\n",
        "\n",
        "        Returns:\n",
        "\n",
        "        \"\"\"\n",
        "        sample_df = sample_key.groupby(\n",
        "            [\"Target Name\", \"Target Setting Specimen Type\"], group_keys=False\n",
        "        ).apply(self.check_cutoffs, adf_df)\n",
        "\n",
        "        return sample_df\n",
        "\n",
        "    @staticmethod\n",
        "    def classification(expected_result: str, observed_result: str) -> Union[str, None]:\n",
        "        \"\"\"This function takes the value from the expected result and the simulated target results column\n",
        "        and uses them to determine if that sample row is TP, TN, FN, FP\n",
        "\n",
        "        Args:\n",
        "            expected_result: a string that is either \"POS\" or \"NEG\"\n",
        "            observed_result: as string that is either \"POS\" or \"NEG\"\n",
        "\n",
        "        Returns: String either True positive (TP), True Negative(TN), False Positive(FP) or False Negative(FN)\n",
        "\n",
        "        \"\"\"\n",
        "        positive_result = \"POS\"\n",
        "        negative_result = \"NEG\"\n",
        "        if expected_result == positive_result and observed_result == positive_result:\n",
        "            return \"TP\"\n",
        "        elif expected_result == negative_result and observed_result == positive_result:\n",
        "            return \"FP\"\n",
        "        elif expected_result == negative_result and observed_result == negative_result:\n",
        "            return \"TN\"\n",
        "        else:\n",
        "            return \"FN\"\n",
        "\n",
        "    def vectorize_classification(self, sample_key_df: pd.DataFrame) -> pd.DataFrame:\n",
        "        \"\"\"This function preforms the classification function on all rows in the dataframe comparing the expected results\n",
        "         column to the observed result column.\n",
        "\n",
        "        Args:\n",
        "            sample_key_df: sample data\n",
        "\n",
        "        Returns: sample key dataframe with a new classification column\n",
        "\n",
        "        \"\"\"\n",
        "        sample_key_df[\"Classification\"] = np.vectorize(self.classification)(\n",
        "            sample_key_df[\"Expected Result\"], sample_key_df[\"Observed Result\"]\n",
        "        )\n",
        "        return sample_key_df\n",
        "\n",
        "    def sensitivity_specificity_calculations(\n",
        "        self, vectorized_sample_key: pd.DataFrame, setting: int\n",
        "    ) -> dict:\n",
        "        \"\"\"This function takes a vectorized sample key dataframe. That means the sample key has a classification column,\n",
        "        it creates a slice of that dataframe that has only the channel of interest and specimen type. It then places the\n",
        "        counts of the values in the classification column into a series. the series is turned into a dictionary.\n",
        "        Sensitivity and specificity are set to zero. and if any of the necessary values (TN,FN,TP,FP) are not in the\n",
        "        dictionary they are added and set to zero. if TP is not zero then sensitivity is calculated. If TN is not\n",
        "        zero specificity is calculated. The youden index is  next. All calculations are values are in a dictionary.\n",
        "\n",
        "        Args:\n",
        "            vectorized_sample_key:\n",
        "            setting:\n",
        "\n",
        "        Returns:\n",
        "\n",
        "        \"\"\"\n",
        "        channel_specimen_type_df = vectorized_sample_key.loc[\n",
        "            (vectorized_sample_key[\"Channel\"] == self.channel)\n",
        "            & (\n",
        "                vectorized_sample_key[\"Target Setting Specimen Type\"]\n",
        "                == self.specimen_type\n",
        "            )\n",
        "        ]\n",
        "        class_counts = channel_specimen_type_df[\"Classification\"].value_counts()\n",
        "        class_counts_dict = class_counts.to_dict()\n",
        "        sensitivity = 0\n",
        "        specificity = 0\n",
        "        if \"TP\" not in class_counts_dict:\n",
        "            class_counts_dict[\"TP\"] = 0\n",
        "        if \"TN\" not in class_counts_dict:\n",
        "            class_counts_dict[\"TN\"] = 0\n",
        "        if \"FN\" not in class_counts_dict:\n",
        "            class_counts_dict[\"FN\"] = 0\n",
        "        if \"FP\" not in class_counts_dict:\n",
        "            class_counts_dict[\"FP\"] = 0\n",
        "\n",
        "        if class_counts_dict[\"TP\"] != 0:\n",
        "            sensitivity = class_counts_dict[\"TP\"] / (\n",
        "                class_counts_dict[\"TP\"] + class_counts_dict[\"FN\"]\n",
        "            )\n",
        "        if class_counts_dict[\"TN\"] != 0:\n",
        "            specificity = class_counts_dict[\"TN\"] / (\n",
        "                class_counts_dict[\"TN\"] + class_counts_dict[\"FP\"]\n",
        "            )\n",
        "\n",
        "        youden_index = sensitivity + specificity - 1\n",
        "        settings_dict = {\n",
        "            \"setting\": setting,\n",
        "            \"True Negatives\": class_counts_dict[\"TN\"],\n",
        "            \"True Positives\": class_counts_dict[\"TP\"],\n",
        "            \"False Negatives\": class_counts_dict[\"FN\"],\n",
        "            \"False Positives\": class_counts_dict[\"FP\"],\n",
        "            \"Analytical Sensitivity\": sensitivity,\n",
        "            \"Analytical Specificity\": specificity,\n",
        "            \"1-Analytical Specificity\": (1 - specificity),\n",
        "            \"Youden Index\": youden_index,\n",
        "        }\n",
        "        return settings_dict\n",
        "\n",
        "    def increment_calculations(self) -> None:\n",
        "        \"\"\"increment_calculations takes the increment list and parses through it. for each value in the increment list,\n",
        "        the parameter of choice is set to the value, and group_by_cutoffs, vectorize_classification, and\n",
        "         sensitivity_specificity_calc is applied to the dataset. the dictionary that is returned from the last function\n",
        "         is placed in a list. The list is turned into a dataframe.\n",
        "        \"\"\"\n",
        "        sample_key = self.sample_key.copy()\n",
        "        adf_df = self.adf_df.copy()\n",
        "        target_name = sample_key.loc[\n",
        "            sample_key[\"Channel\"] == self.channel, \"Target Name\"\n",
        "        ].values[0]\n",
        "\n",
        "        sample_key.replace(\"\", np.nan)\n",
        "        settings_dict_list = []\n",
        "        for i in self.increment_list:\n",
        "            adf_df.loc[\n",
        "                (\n",
        "                    (adf_df[\"TargetName\"] == target_name)\n",
        "                    & (adf_df[\"SpecimenType\"] == self.specimen_type)\n",
        "                ),\n",
        "                self.parameter,\n",
        "            ] = i\n",
        "            grouped_sample_key = self.group_by_cutoffs(sample_key, self.adf_df)\n",
        "            vectorized_sample_key = self.vectorize_classification(grouped_sample_key)\n",
        "            setting_dict = self.sensitivity_specificity_calculations(\n",
        "                vectorized_sample_key, i\n",
        "            )\n",
        "            settings_dict_list.append(setting_dict)\n",
        "\n",
        "        self.settings_df = pd.DataFrame(settings_dict_list)\n",
        "        adf_df[self.parameter] = self.adf_df[self.parameter]\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from typing import Any\n",
        "def target_results_calculations(\n",
        "    sample_key: pd.DataFrame,\n",
        "    adf_df: pd.DataFrame,\n",
        "    specimen_type: str,\n",
        "    channel: str,\n",
        "    parameter: str,\n",
        "    start: int,\n",
        "    end: int,\n",
        "    increment: int,\n",
        ") -> Any:\n",
        "    \"\"\"\n",
        "    target_results_calculations takes 2 dataframes (sample_key file and ADF), specimen type, channel, parameter, start,\n",
        "    end and increment as parameters. The start, end and increment are used to make a list of settings using np.arange.\n",
        "    Then an adf_calc_engine object is created with that list as well as all the other parameters. This object is used\n",
        "    to return a pandas dataframe that has True Negatives counts, True Positives, False Negatives, False Positives,\n",
        "    Analytical Sensitivity, Analytical Specificity, 1-Analytical Specificity, Youden Index.\n",
        "    Args:\n",
        "        sample_key: sample_key dataframe\n",
        "        adf_df: adf dataframe\n",
        "        parameter:a parameter from the adf\n",
        "        channel: includes yellow, red, far_red, green orange.\n",
        "        specimen_type: either option is UserSpecified1 or TransportMedium\n",
        "        start: an integer\n",
        "        increment: an integer\n",
        "        end: and integer\n",
        "\n",
        "    Returns: a dataframe that has sensitivity specificity calculations for each setting\n",
        "\n",
        "    \"\"\"\n",
        "\n",
        "    increment_list = list(np.arange(int(start), int(end), int(increment)))\n",
        "\n",
        "    calc_obj = ADFCalculations(\n",
        "        sample_key=sample_key,\n",
        "        adf_df=adf_df,\n",
        "        parameter=parameter,\n",
        "        specimen_type=specimen_type,\n",
        "        channel=channel,\n",
        "        increment_list=increment_list,\n",
        "    )\n",
        "\n",
        "    return calc_obj"
      ],
      "metadata": {
        "id": "GZrNALR8TNR4"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from typing import Union, TextIO\n",
        "from io import BytesIO\n",
        "from pathlib import Path\n",
        "\n",
        "pd.set_option(\"display.max_columns\", None)\n",
        "pd.set_option(\"display.width\", None)\n",
        "\n",
        "\n",
        "def import_sample_key(sample_key: Union[str, Path, TextIO, BytesIO]) -> pd.DataFrame:\n",
        "    \"\"\"Read in and validate a  dataset\n",
        "    Args:\n",
        "        file path string\n",
        "    Returns:\n",
        "        pandas Dataframe\n",
        "    Raises:\n",
        "        ValueError: If data_set is missing required columns.\n",
        "    \"\"\"\n",
        "    sample_key_cols = (\n",
        "        \"Target Setting Specimen Type\",\n",
        "        \"Sample ID\",\n",
        "        \"Channel\",\n",
        "        \"Target Name\",\n",
        "        \"Assay Name\",\n",
        "        \"Assay Version\",\n",
        "        \"Localized Result\",\n",
        "        \"Expected Result\",\n",
        "        \"Ct\",\n",
        "        \"End Point Fluorescence\",\n",
        "        \"EPR\",\n",
        "        \"Max Peak Height\",\n",
        "        \"Flags\",\n",
        "    )\n",
        "\n",
        "    sample_data: pd.DataFrame = pd.read_excel(\n",
        "        sample_key,\n",
        "    )\n",
        "    sample_data.astype(\n",
        "        {\n",
        "            \"Ct\": float,\n",
        "            \"End Point Fluorescence\": float,\n",
        "            \"EPR\": float,\n",
        "            \"Max Peak Height\": float,\n",
        "        }\n",
        "    )\n",
        "    sample_data = sample_data.replace(np.nan, \"\", regex=True)\n",
        "    #roc.validate_required_columns(required_columns=sample_key_cols, df=sample_data)\n",
        "    return sample_data"
      ],
      "metadata": {
        "id": "7b_CYjG3Ts23"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from typing import Union, Any\n",
        "from pathlib import Path\n",
        "from io import BytesIO\n",
        "import pandas as pd\n",
        "\n",
        "\n",
        "class ADFParser:\n",
        "    \"\"\"\n",
        "    A class used to parse and store data related to a NeuMoDx ADF RawDataExport File\n",
        "    \"\"\"\n",
        "\n",
        "    adf_clean_dataframes: dict[Any, Any]\n",
        "    adf_tabs: list[Any]\n",
        "    adf_raw_dataframes: dict[Any, Any]\n",
        "\n",
        "    def __init__(self, filename: Union[str, Path, BytesIO]) -> None:\n",
        "        self.filename = filename\n",
        "        self.adf_tabs = []\n",
        "        self.adf_raw_dataframes = {}\n",
        "        self.adf_clean_dataframes = {}\n",
        "        self.get_all_adf_data()\n",
        "\n",
        "    @staticmethod\n",
        "    def get_adf_tabs(filepath: Union[str, Path, BytesIO]) -> list[str]:\n",
        "        \"\"\"\n",
        "        A function used to retrieve the ADF tabs from a NeuMoDx RawDataExport File.\n",
        "\n",
        "        Args:\n",
        "          filepath (str): Name of the NeuMoDx RawDataExport File to read from.\n",
        "\n",
        "        Returns:\n",
        "          list[str]: A list of sheet names that are the ADF tabs found in the File.\n",
        "        \"\"\"\n",
        "        # Create Excel file Object from the filepath\n",
        "        xls_file = pd.ExcelFile(filepath)\n",
        "\n",
        "        # Get the sheet names that correspond to ADF Tabs\n",
        "        adf_sheet_names = [x for x in xls_file.sheet_names if \"ADF\" in x]\n",
        "        if len(adf_sheet_names) == 0:\n",
        "            raise ValueError(\"File uploaded must include ADFs\")\n",
        "\n",
        "        return adf_sheet_names\n",
        "\n",
        "    @staticmethod\n",
        "    def read_adf_tab(\n",
        "        filepath: Union[str, Path, BytesIO], sheet_name: str\n",
        "    ) -> pd.DataFrame:\n",
        "        \"\"\"\n",
        "        A function used to read the data contained in ADF Tab into a pandas DataFrame.\n",
        "\n",
        "        Args:\n",
        "         filepath (str): Name of the NeuMoDx RawDataExport File to read from.\n",
        "         sheet_name (str): Name of sheet containing ADF Data.\n",
        "\n",
        "        Returns:\n",
        "         pd.Dataframe: DataFrame Representation of the ADF Tab\n",
        "        \"\"\"\n",
        "        # Read data associated with the adf_tab into a Dataframe\n",
        "        adf_raw_dataframe = pd.read_excel(filepath, sheet_name=sheet_name)[\n",
        "            [\"Key\", \"Value\"]\n",
        "        ]\n",
        "        return adf_raw_dataframe\n",
        "\n",
        "    def clean_adf_data(self, adf_raw_dataframe: pd.DataFrame) -> pd.DataFrame:\n",
        "        \"\"\"\n",
        "        A function used to clean the raw data from the ADF tab into a more usable Data\n",
        "\n",
        "        Args:\n",
        "          adf_raw_dataframe (pd.DataFrame): adf_raw_dataframe to be cleaned.\n",
        "\n",
        "        Returns:\n",
        "          pd.DataFrame: A cleaned representation of the adf dataframe.\n",
        "        \"\"\"\n",
        "        #\n",
        "        adf_clean_dataframe = drop_excess_rows(adf_raw_dataframe)\n",
        "        # Create a new column corresponding to the TargetName:\n",
        "        adf_clean_dataframe[\"TargetName\"] = self.get_series_substring(\n",
        "            input_series=adf_clean_dataframe[\"Key\"].values,\n",
        "            start_substring=\"XPCR Target \",\n",
        "            end_substring=\" Setting\",\n",
        "        )\n",
        "\n",
        "        # Create a new column corresponding to the SpecimenType:\n",
        "        adf_clean_dataframe[\"SpecimenType\"] = self.get_series_substring(\n",
        "            input_series=adf_clean_dataframe[\"Key\"].values,\n",
        "            start_substring=\"SpecimenType \",\n",
        "            end_substring=\" - \",\n",
        "        )\n",
        "\n",
        "        # Create a new column corresponding to the Parameter name:\n",
        "        adf_clean_dataframe[\"Parameter\"] = self.get_series_substring(\n",
        "            input_series=adf_clean_dataframe[\"Key\"].values, start_substring=\" - \"\n",
        "        )\n",
        "\n",
        "        # Set Index to the individual properties parsed from the Key Column\n",
        "        adf_clean_dataframe.set_index(\n",
        "            [\"TargetName\", \"SpecimenType\", \"Parameter\"], inplace=True\n",
        "        )\n",
        "\n",
        "        # Drop the Key Column\n",
        "        adf_clean_dataframe.drop(\"Key\", axis=1, inplace=True)\n",
        "\n",
        "        # Pivot DataFrame to new format\n",
        "        adf_clean_dataframe = adf_clean_dataframe.reset_index().pivot(\n",
        "            index=[\"TargetName\", \"SpecimenType\"], columns=[\"Parameter\"], values=\"Value\"\n",
        "        )\n",
        "        adf_clean_dataframe.reset_index(inplace=True)\n",
        "        return adf_clean_dataframe\n",
        "\n",
        "    @staticmethod\n",
        "    def get_series_substring(\n",
        "        input_series: pd.Series,\n",
        "        start_substring: str | None = None,\n",
        "        end_substring: str | None = None,\n",
        "    ) -> list[Any]:\n",
        "        \"\"\"\n",
        "        A function used to create a new column based on a string found between\n",
        "         a start_substring and end_substring contained in the pandas Series\n",
        "\n",
        "        Args:\n",
        "          input_series (pd.Series): Series to be parsed.\n",
        "          start_substring (str|None): Text to serve as the minimum boundary.\n",
        "          end_substring (str|None): Text substring to server as the maximum boundary.\n",
        "        Returns:\n",
        "          pd.Series: A series corresponding the values between the start and end boundaries\n",
        "\n",
        "\n",
        "        \"\"\"\n",
        "\n",
        "        # Case handling for both start_string and end_substring defined.\n",
        "        new_series_values = []\n",
        "        if start_substring and end_substring:\n",
        "            new_series_values = [\n",
        "                x[\n",
        "                    x.find(start_substring)\n",
        "                    + len(start_substring) : x.find(end_substring)\n",
        "                ]\n",
        "                for x in input_series\n",
        "            ]\n",
        "\n",
        "        # Case handling for start_string defined and end_substring not defined.\n",
        "        elif start_substring and not end_substring:\n",
        "            new_series_values = [\n",
        "                x[x.find(start_substring) + len(start_substring) :]\n",
        "                for x in input_series\n",
        "            ]\n",
        "\n",
        "        # Case handling for start_string not defined and end_substring defined.\n",
        "        elif not start_substring and end_substring:\n",
        "            new_series_values = [x[: x.find(end_substring)] for x in input_series]\n",
        "\n",
        "        return new_series_values\n",
        "\n",
        "    def get_all_adf_data(self) -> None:\n",
        "        \"\"\"\n",
        "        A function used to parse and clean all ADF data associated with a NeuMoDx Raw Data Export File.\n",
        "        Returns:\n",
        "\n",
        "        \"\"\"\n",
        "\n",
        "        self.adf_tabs = self.get_adf_tabs(filepath=self.filename)\n",
        "\n",
        "        for adf in self.adf_tabs:\n",
        "            self.adf_raw_dataframes[adf] = self.read_adf_tab(\n",
        "                filepath=self.filename, sheet_name=adf\n",
        "            )\n",
        "            self.adf_clean_dataframes[adf] = self.clean_adf_data(\n",
        "                adf_raw_dataframe=self.adf_raw_dataframes[adf]\n",
        "            )\n",
        "\n",
        "\n",
        "def drop_excess_rows(df: pd.DataFrame) -> pd.DataFrame:\n",
        "    \"\"\"\n",
        "    Args:\n",
        "        df: pandas dataframe with key and value columns\n",
        "    Returns:\n",
        "        pd.Dataframe\n",
        "    \"\"\"\n",
        "    df[\"sample_info\"] = df[\"Key\"].apply(key_string_bool)\n",
        "    false_index_values = df[(df[\"sample_info\"] == False)].index\n",
        "    df.drop(false_index_values, inplace=True)\n",
        "    df.drop(columns=\"sample_info\", inplace=True)\n",
        "    return df\n",
        "\n",
        "\n",
        "def key_string_bool(adf_key_string: str) -> bool:\n",
        "    \"\"\"\n",
        "    Args:\n",
        "        adf_key_string: a string from the key column that\n",
        "         contains information on specimen type and target\n",
        "    Returns:\n",
        "        this function returns True or False\n",
        "    \"\"\"\n",
        "\n",
        "    if \"xpcr target\" and \"specimentype\" in adf_key_string.lower():\n",
        "        return True\n",
        "    else:\n",
        "        return False\n"
      ],
      "metadata": {
        "id": "OkYxrTaOUSYe"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "increment_list = list(np.arange(0,100,5))\n",
        "parameter = \"Peak Maximum Cycle\"\n",
        "Channel = \"Yellow\"\n",
        "Specimen_type = \"UserSpecified1\""
      ],
      "metadata": {
        "id": "7YZwt2QMT8wz"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sample_key = import_sample_key(\"/content/sample_data/Combined_Channels_sample_key.xlsx\")"
      ],
      "metadata": {
        "id": "diXQXVOcT-8M"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "adf_obj = ADFParser(\"/content/sample_data/RawDataExport.96-3.96000003.2208021509.8EB890A6.xlsx\")"
      ],
      "metadata": {
        "id": "09XDW4HmULjM"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "adf_df = adf_obj.adf_clean_dataframes[adf_obj.adf_tabs[0]]"
      ],
      "metadata": {
        "id": "gX_qRzsRUdCa"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "adf_calc = ADFCalculations(sample_key,adf_df,parameter,Channel,Specimen_type,increment_list)"
      ],
      "metadata": {
        "id": "iZbMiwhXUkUQ"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from plotly.subplots import make_subplots\n",
        "import plotly.graph_objects as go"
      ],
      "metadata": {
        "id": "DkFMC9y3UpBX"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "settings_df = adf_calc.settings_df\n",
        "settings_df.head(3)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 143
        },
        "id": "bo6o3sbXUuz5",
        "outputId": "40539986-c672-430b-aaa4-514bf95c4384"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   setting  True Negatives  True Positives  False Negatives  False Positives  \\\n",
              "0        0              23               5               33                6   \n",
              "1        5              23               5               33                6   \n",
              "2       10              23               5               33                6   \n",
              "\n",
              "   Analytical Sensitivity  Analytical Specificity  1-Analytical Specificity  \\\n",
              "0                0.131579                0.793103                  0.206897   \n",
              "1                0.131579                0.793103                  0.206897   \n",
              "2                0.131579                0.793103                  0.206897   \n",
              "\n",
              "   Youden Index  \n",
              "0     -0.075318  \n",
              "1     -0.075318  \n",
              "2     -0.075318  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-33b236bf-c07f-48db-adae-5c9a572a8a6e\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>setting</th>\n",
              "      <th>True Negatives</th>\n",
              "      <th>True Positives</th>\n",
              "      <th>False Negatives</th>\n",
              "      <th>False Positives</th>\n",
              "      <th>Analytical Sensitivity</th>\n",
              "      <th>Analytical Specificity</th>\n",
              "      <th>1-Analytical Specificity</th>\n",
              "      <th>Youden Index</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>23</td>\n",
              "      <td>5</td>\n",
              "      <td>33</td>\n",
              "      <td>6</td>\n",
              "      <td>0.131579</td>\n",
              "      <td>0.793103</td>\n",
              "      <td>0.206897</td>\n",
              "      <td>-0.075318</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>5</td>\n",
              "      <td>23</td>\n",
              "      <td>5</td>\n",
              "      <td>33</td>\n",
              "      <td>6</td>\n",
              "      <td>0.131579</td>\n",
              "      <td>0.793103</td>\n",
              "      <td>0.206897</td>\n",
              "      <td>-0.075318</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>10</td>\n",
              "      <td>23</td>\n",
              "      <td>5</td>\n",
              "      <td>33</td>\n",
              "      <td>6</td>\n",
              "      <td>0.131579</td>\n",
              "      <td>0.793103</td>\n",
              "      <td>0.206897</td>\n",
              "      <td>-0.075318</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-33b236bf-c07f-48db-adae-5c9a572a8a6e')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-33b236bf-c07f-48db-adae-5c9a572a8a6e button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-33b236bf-c07f-48db-adae-5c9a572a8a6e');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "fig = go.Figure()\n",
        "fig.add_trace(\n",
        "    go.Scatter(x=settings_df[\"setting\"], y=settings_df[\"Analytical Sensitivity\"],name=\"Senstivity\",mode='lines+markers')\n",
        ")\n",
        "fig.add_trace(\n",
        "    go.Scatter(x=settings_df[\"setting\"],y=settings_df[\"Analytical Specificity\"],name=\"Specificity\",mode='lines+markers')\n",
        ")\n",
        "fig.update_layout(title='Variation of Analytical Sensitivity/ Specificity',\n",
        "                   yaxis_title='Sensitivity/Specficity',\n",
        "                   xaxis_title=\"{0}\".format(parameter))\n",
        "\n"
      ],
      "metadata": {
        "id": "WlOV8cl2Uy2V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fig1 = go.Figure()\n",
        "fig1.add_trace(\n",
        "    go.Scatter(x=settings_df[\"1-Analytical Specificity\"], y=settings_df[\"Analytical Sensitivity\"],name=\"Senstivity (True Positive Rate)\",mode='lines+markers')\n",
        ")\n",
        "\n",
        "fig1.update_layout(title='ROC Curve',\n",
        "                   xaxis_title='1-Specificity(False Positive Rate)',\n",
        "                   yaxis_title=\"Sensitivity(True Positive Rate)\")"
      ],
      "metadata": {
        "id": "S9ihUpq5ZtLg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fig2 = go.Figure()\n",
        "fig2.add_trace(\n",
        "    go.Scatter(x=settings_df[\"setting\"], y=settings_df[\"Youden Index\"],name=\"Youden Index\",mode='lines+markers')\n",
        ")\n",
        "\n",
        "fig2.update_layout(title='Youden Index',\n",
        "                   yaxis_title='Youden Index(Sensitivity+Specificity-1)',\n",
        "                   xaxis_title=\"{0}\".format(parameter))"
      ],
      "metadata": {
        "id": "0cio3SMtebGS"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}